{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'ignore_mismatched_sizes': True} are not expected by StableDiffusionInstructPix2PixPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e9977e37cd4752b084369d0832a617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_instruct_pix2pix.StableDiffusionInstructPix2PixPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os\n",
    "\n",
    "os.chdir(\"/home/ubuntu/4catalyzer-hackathon\")\n",
    "\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline\n",
    "\n",
    "device = \"cuda\"\n",
    "# model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
    "model_id_or_path = \"./opt/run-overnight\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16, low_cpu_mem_usage=False, ignore_mismatched_sizes=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "\n",
    "prompts = {\n",
    "    \"h2h\": \"This is an image of a normal brain MRI scan from axial view. It should be grey scale and clearly show brain structure. Do not modify the input image.\",\n",
    "    \"h2uh\": \"Given an input image of a normal brain MRI scan from axial view, modify the image by inserting a brain lesion within the MRI image. This brain lesion is caused by an ischaemic stroke. The lesion should appear relatively lighter compared to its surroundings brain tissue in the image.\",\n",
    "    \"uh2uhm\": \"Given an input image of an unhealthy brain MRI scan from axial view that contains brain lesions, modify the image to colour the lesions light red.\",\n",
    "    \"h2uhm\": \"Given an input image of a normal brain MRI scan from axial view, modify the image by inserting a brain lesion within the MRI image, and colour the lesions light red. This brain lesion is caused by an ischaemic stroke.\",\n",
    "    \"uhm2uhm\": \"This is an image of an unhealthy brain MRI scan from axial view that contains brain lesions. The lesions are coloured light red.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75a0e5d74f348f69d648aefd880157f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb4567686a349f49adb96083ca90704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611bdd51ee2b48c5aa980f79d9c8183a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083f24edc71645b997abe978cb096265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb1dc199ba947debb964fa3a7d70328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc9eadd903845b4987b2fbd1a3010af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56881f1515845b0b15060537480adba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Assuming the 'data' folder is in the same directory as your script\n",
    "data_folder = \"./data/train/\"\n",
    "\n",
    "# # Replace 'sketch-mountains-input.jpg' with the actual filename if needed\n",
    "image_filename = 'healthy_images/sub-ON21834/caseON21834_dwi_slice_40.png'\n",
    "\n",
    "# Replace 'sketch-mountains-input.jpg' with the actual filename if needed\n",
    "# image_filename = 'lesion_images/sub-strokecase0002/case0002_dwi_slice_30.png'\n",
    "\n",
    "# Build the full path to the image file\n",
    "image_path = os.path.join(data_folder, image_filename)\n",
    "\n",
    "# Open and resize the image\n",
    "init_image = Image.open(image_path).convert(\"RGB\")\n",
    "# init_image = init_image.resize((768, 512))\n",
    "\n",
    "# prompt = prompts[\"h2uhm\"]\n",
    "prompt = \"modify the image by inserting brain lesions within the MRI image, and highlight the brain lesions in bright red color.\"\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(40)\n",
    "\n",
    "\n",
    "start_steps = 20\n",
    "max_num_inference_steps = 160\n",
    "os.system(\"rm -rf ./viz/\")\n",
    "os.system(\"mkdir ./viz/\")\n",
    "\n",
    "steps=80\n",
    "guidance_scale = 5.5\n",
    "image_guidance_scale = 7.0\n",
    "for steps in range(start_steps, max_num_inference_steps, 20):\n",
    "#     for guidance_scale in range(2, 15):\n",
    "    healthy_output_file = os.path.basename(image_filename)\n",
    "    output_path = f\"./viz/{healthy_output_file}\"\n",
    "    init_image.save(output_path)\n",
    "\n",
    "    images = pipe(prompt, image=init_image,\n",
    "          num_inference_steps = steps,\n",
    "          image_guidance_scale = image_guidance_scale,\n",
    "          guidance_scale = guidance_scale,\n",
    "          num_images_per_prompt=1,\n",
    "          generator=generator).images\n",
    "    for idx, image in enumerate(images):\n",
    "        pred_output_path = f\"./viz/{os.path.splitext(os.path.basename(image_filename))[0]}-generated-{idx}-step-{steps}-guiding-scale-{guidance_scale}.jpg\"\n",
    "        image.save(pred_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def create_video_from_directory(image_directory, output_video_path, frame_rate):\n",
    "    image_files = sorted([f for f in os.listdir(image_directory) if f.endswith('.jpg')])  # Modify the extension as needed\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the directory.\")\n",
    "        return\n",
    "\n",
    "    first_image_path = os.path.join(image_directory, image_files[0])\n",
    "    image = cv2.imread(first_image_path)\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for the output video, modify as needed\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height))\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_directory, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        out.write(image)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video created successfully at {output_video_path}\")\n",
    "\n",
    "# Example usage:\n",
    "image_directory = './viz/'\n",
    "output_video_path = './viz/video-3.mp4'\n",
    "frame_rate = 1  # Adjust the frame rate as needed\n",
    "\n",
    "create_video_from_directory(image_directory, output_video_path, frame_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
